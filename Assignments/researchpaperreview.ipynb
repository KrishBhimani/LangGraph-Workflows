{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['GROQ_API_KEY']=os.getenv('GROQ_API_KEY')\n",
    "llm=ChatGroq(model=\"qwen-2.5-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The provided text introduces a technical paper titled \"Attention Is All You Need,\" authored by a group of researchers primarily from Google Brain and Google Research. The introduction includes a permission statement that allows for the reproduction of the figures and tables from the paper, provided that proper attribution is given, and it is used for journalistic or scholarly purposes. This is a standard practice in academic and research communities to ensure the integrity and attribution of intellectual property.\n",
       "\n",
       "The abstract of the paper succinctly outlines the main contribution: the introduction of the Transformer model, which is a novel approach to sequence transduction. Sequence transduction, in the context of natural language processing and machine learning, refers to the process of converting one sequence of symbols into another. Traditionally, models for sequence transduction have relied heavily on complex recurrent neural networks (RNNs) or convolutional neural networks (CNNs), which are structured to process sequential data. These models often incorporate encoder-decoder architectures, which separate the processing of input sequences (encoding) from the generation of output sequences (decoding).\n",
       "\n",
       "The paper's key innovation is the Transformer model, which entirely eliminates the dependency on recurrence and convolution, instead relying solely on attention mechanisms for sequence processing. Attention mechanisms allow the model to selectively focus on different parts of the input sequence when predicting each part of the output sequence, potentially improving the model's performance and efficiency. By doing away with recurrence and convolutions, the Transformer model proposes a simpler yet powerful architecture that could potentially revolutionize the way sequence transduction tasks are approached and executed in the field of machine learning and natural language processing.\n",
       "\n",
       "---\n",
       "\n",
       "The section introduces a novel approach to network architecture by proposing the Transformer model, which relies entirely on attention mechanisms, thus eliminating the need for traditional recurrence and convolutional layers. This shift in architectural design is significant because it addresses the limitations associated with recurrent neural networks (RNNs) and convolutional neural networks (CNNs), such as their sequential nature and computational complexity, respectively. The Transformer's design allows for greater parallelization, which significantly reduces training times and enhances computational efficiency.\n",
       "\n",
       "The effectiveness of the Transformer is demonstrated through its performance on two machine translation tasks from the WMT 2014 benchmarks: English-to-German and English-to-French. The model achieves state-of-the-art results, with a BLEU score of 28.4 for English-to-German, surpassing previous best results by more than 2 BLEU points. For English-to-French, it achieves a BLEU score of 41.8, establishing a new single-model record. These advancements are particularly noteworthy given the reduced computational resources required, achieving these results after only 3.5 days of training on eight GPUs compared to the substantial resources typically needed for competitive models.\n",
       "\n",
       "Moreover, the versatility of the Transformer is highlighted by its successful application to a non-translation task, specifically English constituency parsing. This broad applicability underscores the model's robustness and adaptability across different natural language processing (NLP) tasks, even in scenarios with limited training data. The results suggest that the Transformer not only outperforms previous models in translation tasks but also offers a promising framework for a variety of NLP applications, potentially revolutionizing the field by providing a more efficient and effective modeling approach.\n",
       "\n",
       "---\n",
       "\n",
       "This section of the text outlines the contributions of multiple researchers to the development and evaluation of the Transformer model, a key advancement in natural language processing (NLP). The Transformer model, which relies heavily on self-attention mechanisms, was shown to outperform recurrent neural network (RNN) models in several NLP tasks, including English constituency parsing. This success was demonstrated under different data conditions, showcasing the robustness and generalization capabilities of the Transformer.\n",
       "\n",
       "In terms of contributions, the research team is noted for their collective effort, with each member playing a pivotal role. Jakob, for instance, proposed replacing RNNs with self-attention mechanisms, setting the foundational direction for the project. Ashish and Illia are credited with designing and implementing the first versions of the Transformer, contributing significantly to all aspects of the research. Noam's contributions are highlighted through his innovations in attention mechanisms, such as scaled dot-product attention and multi-head attention, which are integral to the model's architecture. Niki's extensive work on model design, implementation, tuning, and evaluation is emphasized, particularly within the context of the original codebase and the tensor2tensor framework. Llion's innovative experiments and development of the initial codebase, alongside his contributions to inference efficiency and visualizations, are also noted. The dedication of Lukasz and Aidan, who worked extensively on various parts of the model, is recognized for their significant contributions to the Transformer's development.\n",
       "\n",
       "The collaborative nature of the project is evident, with each member's expertise contributing to the success and versatility of the Transformer model. This collective effort has not only advanced the field of NLP but has also set a new standard for model design and evaluation, particularly in handling sequential data.\n",
       "\n",
       "---\n",
       "\n",
       "The chunk provided appears to be part of an academic paper, likely within the field of machine learning or natural language processing. It is from the introduction of a paper presented at the 31st Conference on Neural Information Processing Systems (NIPS 2017) and was posted on arXiv on August 2, 2023, with the identifier arXiv:1706.03762v7. The introduction establishes the context and significance of recurrent neural networks (RNNs), particularly focusing on long short-term memory (LSTM) networks and gated recurrent units (GRU), which are noted as state-of-the-art methods for sequence modeling and transduction tasks such as language modeling and machine translation. The section also mentions the ongoing advancements in these models and architectures, referencing several key studies that have contributed to these developments.\n",
       "\n",
       "However, the first paragraph of the chunk is somewhat confusing and fragmented, discussing the efforts of individuals named Lukasz and Aidan in developing and implementing tensor2tensor, a framework for machine learning. This part seems out of place within the introduction's flow and is not clearly connected to the subsequent content about RNNs and their advancements. It appears to be a separate section or an annotation that has been mistakenly included with the introduction. This section also includes footnotes indicating that the work was performed at Google Brain and Google Research, which provides context about the origin and affiliation of the researchers.\n",
       "\n",
       "The introduction effectively sets the stage for the paper by outlining the importance of RNNs and LSTM/GRU networks in the domain of sequence modeling and transduction, while also highlighting the continuous progress in these areas. However, the inclusion of the tensor2tensor development narrative should be better integrated or separated from the main content to enhance clarity and readability.\n",
       "\n",
       "---\n",
       "\n",
       "In this section, the text delves into the intricacies of architectures used for handling sequential data, particularly focusing on recurrent models and attention mechanisms. Recurrent models, often the backbone of sequence processing, compute hidden states sequentially, with each state \\( h_t \\) being a function of its predecessor \\( h_{t-1} \\) and the current input at position \\( t \\). This sequential processing limits parallelization during training, which becomes a significant bottleneck as sequence lengths increase. The inherent difficulty in parallelizing computations within individual training examples exacerbates memory constraints, thereby limiting the efficiency of batch processing across different examples.\n",
       "\n",
       "Recent advancements have introduced strategies to enhance computational efficiency. Techniques such as factorization tricks and conditional computation have not only improved the computational speed but also, in the case of conditional computation, contributed to better model performance. Despite these innovations, the fundamental limitation of sequential computation persists, indicating the need for more flexible and efficient processing paradigms.\n",
       "\n",
       "Attention mechanisms have emerged as a powerful solution in this landscape. By enabling the model to focus on different parts of the input sequence dynamically, attention mechanisms overcome the limitations of fixed-order sequential processing. This allows for more effective handling of dependencies regardless of their distance within the sequence, thereby improving the modeling of complex relationships in tasks like sequence modeling and transduction. The integration of attention mechanisms has transformed the way dependencies are modeled, providing a more dynamic and efficient approach compared to traditional recurrent architectures.\n",
       "\n",
       "---\n",
       "\n",
       "The section under review focuses on the introduction and background of the Transformer model, a significant advancement in the field of sequence modeling and transduction. The text begins by highlighting the importance of attention mechanisms in managing dependencies within sequences, noting that they are typically employed in conjunction with recurrent neural networks (RNNs). The Transformer architecture, however, represents a novel departure by abandoning recurrence in favor of a purely attention-based approach. This shift is pivotal as it not only simplifies the model’s architecture but also enhances computational efficiency by enabling more extensive parallel processing.\n",
       "\n",
       "The introduction of the Transformer is contextualized within the broader backdrop of efforts to reduce sequential computation, a critical challenge in neural network architectures. The authors mention several models that have attempted to address this issue, such as the Extended Neural GPU, ByteNet, and ConvS2S, all of which utilize convolutional neural networks (CNNs). These models are noted for their approach to overcoming the limitations of RNNs, particularly in terms of handling long-range dependencies and enabling more efficient computation.\n",
       "\n",
       "The section also emphasizes the Transformer’s potential for achieving high translation quality rapidly. Specifically, the text claims that the Transformer can attain state-of-the-art performance in translation tasks after a relatively short training period of twelve hours on eight P100 GPUs. This efficiency is a significant advantage in practical applications where speed and resource utilization are crucial.\n",
       "\n",
       "In summary, this section sets the stage for understanding the Transformer model as a groundbreaking architecture in neural network design, particularly in the realm of sequence processing. It underscores the model's ability to solve problems related to dependency modeling and computational efficiency, positioning it as a superior alternative to previous architectures.\n",
       "\n",
       "---\n",
       "\n",
       "The passage discusses the architectural foundations of several advanced neural network models, specifically the Extended Neural GPU, ByteNet, and ConvS2S, which aim to reduce sequential computation through the use of convolutional neural networks. These models are designed to process input and output positions in parallel, significantly enhancing computational efficiency. However, the relationship between input or output positions in these models becomes computationally more challenging as the distance between positions increases. For ConvS2S, the complexity grows linearly with the distance, while for ByteNet, it grows logarithmically, making it harder for the model to learn dependencies between distant elements.\n",
       "\n",
       "In contrast, the Transformer model addresses these challenges by reducing the number of operations required to relate signals between distant positions to a constant, regardless of the distance. This is achieved through the use of self-attention (or intra-attention) mechanisms, which allow the model to relate different positions within the input or output sequences directly. However, this comes with a trade-off: the averaging of attention-weighted positions can lead to a reduced effective resolution, potentially diminishing the model's ability to capture fine-grained dependencies. To mitigate this issue, the Transformer employs Multi-Head Attention, as detailed in section 3.2. This approach allows the model to maintain high-resolution representations, enhancing its capacity to learn and utilize dependencies across various distances within the sequences. Overall, the Transformer's architectural design improves upon its predecessors by efficiently handling long-range dependencies while maintaining computational efficiency.\n",
       "\n",
       "---\n",
       "\n",
       "The section under review succinctly outlines the evolution and significance of self-attention mechanisms within the broader context of neural network architectures, particularly focusing on their role in enhancing the performance of various natural language processing (NLP) tasks. Self-attention, also known as intra-attention, is a critical component that enables the model to weigh the significance of different parts of an input sequence, allowing for a more nuanced and context-aware representation of the data. This mechanism has proven to be highly effective in a variety of applications such as reading comprehension, abstractive summarization, textual entailment, and learning task-independent sentence representations.\n",
       "\n",
       "Moreover, the section highlights advancements in memory networks, specifically end-to-end memory networks, which leverage recurrent attention mechanisms. These models摒除先前的回答中的不相关部分，专注于修复和增强原始段落的连贯性和清晰度。以下是改进的版本：\n",
       "\n",
       "---\n",
       "\n",
       "自注意力机制，有时也被称为内注意力机制，是一种注意力机制，它将单个序列的不同位置联系起来，以计算该序列的表示。自注意力机制已在多种任务中成功应用，包括阅读理解、抽象性总结、文本蕴含和学习任务独立的句子表示。端到端记忆网络基于循环注意力机制，而非序列对齐的递归结构，在简单的语言问答和语言建模任务中表现出色。然而，据我们所知，Transformer是首个完全依赖自注意力机制来计算输入和输出表示的转换模型，而不使用序列对齐的递归神经网络（RNN）或卷积。在接下来的部分中，我们将详细描述Transformer，并解释其设计动机。\n",
       "\n",
       "---\n",
       "\n",
       "这样修改后，段落更加连贯，重点突出，同时也保留了原始信息的准确性。\n",
       "\n",
       "---\n",
       "\n",
       "The section introduces the Transformer model, a pivotal advancement in the field of neural network architectures, particularly for sequence transduction tasks. It builds upon the standard encoder-decoder framework, which has proven effective in numerous applications such as machine translation and speech recognition. The text emphasizes the Transformer's reliance on self-attention mechanisms, a key innovation that improves upon traditional recurrent neural networks (RNNs) and convolutional architectures. This shift is motivated by the self-attention mechanism's ability to handle long-range dependencies and parallelize more effectively, thus offering significant computational benefits over previous models.\n",
       "\n",
       "In the detailed architectural overview, the Transformer is described as comprising an encoder and a decoder, each structured around self-attention layers and point-wise feed-forward networks. These components are stacked, allowing the model to process inputs in a hierarchical and multi-layered manner. The encoder's role is to transform the input sequence into a series of continuous representations, which are then utilized by the decoder to generate an output sequence. This process is depicted in Figure 1, which visually separates the encoder and decoder components, highlighting the self-attention and feed-forward layers characteristic of the Transformer.\n",
       "\n",
       "The reliance on self-attention and the overall architecture of the Transformer marks a significant departure from previous models like those referenced in [17, 18, and 9], which likely include RNNs and convolutional models. This new architecture not only addresses some of the limitations of these older models but also introduces novel ways of handling sequence data, setting the stage for further discussion on its advantages and applications.\n",
       "\n",
       "---\n",
       "\n",
       "This section discusses the architecture of the encoder and decoder in a transformer model, which are central components for handling sequence data in tasks like translation or text summarization. The design focuses on stacking layers to refine the representations iteratively.\n",
       "\n",
       "In the **encoder** section, the transformer model employs a stack of six (N=6) identical layers, each containing two key sub-layers. The first sub-layer is a multi-head self-attention mechanism, which allows the model to weigh the relevance of different positions in the input sequence to each other. This mechanism is crucial for capturing dependencies within the sequence. The second sub-layer is a position-wise feed-forward network, which processes each position independently and identically. This network applies a linear transformation followed by a non-linearity, enhancing the model's ability to learn complex patterns.\n",
       "\n",
       "Both sub-layers in the encoder are equipped with residual connections and layer normalization. The residual connection helps in mitigating the vanishing gradient problem and enables the model to learn identity mappings more easily. The normalization ensures that the outputs of the sub-layers remain stable, which is beneficial for training deep networks. Notably, the output dimensions of these sub-layers and the embedding layers are standardized to 512 dimensions (dmodel=512), which provides a consistent interface for the information flow within the model.\n",
       "\n",
       "The **decoder** follows a similar design but introduces an additional sub-layer to handle the encoded input from the encoder. This third sub-layer, which performs multi-head attention over the output of the encoder, allows the decoder to incorporate context from the encoder into its own self-attention process. This is particularly useful in tasks that require understanding the entire context of the input sequence, like in translation. The same principles of residual connections and layer normalization are applied to ensure stable and effective learning.\n",
       "\n",
       "Overall, this architectural design, with its modular sub-layers and normalization techniques, supports the transformer model's capability to effectively process and generate sequence data, making it a powerful tool in natural language processing and other sequence-oriented tasks.\n",
       "\n",
       "---\n",
       "\n",
       "The decoder component of the model described is intricately designed to handle sequential data, particularly in tasks such as translation or text generation, where the output at each step depends on the previously generated outputs. It employs a stack of N = 6 identical layers, each with a unique structure that distinguishes it from its encoder counterpart. Specifically, the decoder features an additional sub-layer that performs multi-head attention over the encoder's output, which is crucial for incorporating context from the input sequence into the output sequence.\n",
       "\n",
       "The architecture of these layers is further refined by the use of residual connections and layer normalization. These mechanisms are essential for stabilizing the training process by mitigating the vanishing gradient problem and ensuring that each layer's input and output remain on a comparable scale. This design choice helps in enhancing the model's capacity to learn long-range dependencies and maintain the integrity of the information flow across layers.\n",
       "\n",
       "A key aspect of the decoder is the masking technique applied to the self-attention mechanism. This ensures that each position in the sequence can only attend to and be influenced by the positions that precede it in the sequence. This forward-looking restriction is vital in maintaining the integrity of the autoregressive generation process, allowing the model to generate the next word based solely on the words that have already been generated.\n",
       "\n",
       "The concept of attention, further detailed in the section, is pivotal to the model's ability to focus on different parts of the input sequence when generating each part of the output. Attention functions compute an output by taking a query and a set of key-value pairs, where the output is a weighted sum of the values, with the weights determined by the compatibility of the query with each key. This mechanism enables the model to dynamically weigh the importance of different input elements for generating each output element, thereby enhancing its ability to capture complex relationships within the data.\n",
       "\n",
       "In summary, the described decoder architecture, through its use of multi-head attention, residual connections, and positional masking, equips the model with robust capabilities for handling sequential data with a strong focus on context and dependency, making it well-suited for tasks requiring a deep understanding of sequence information.\n",
       "\n",
       "---\n",
       "\n",
       "The section under review delves into the mechanism of attention in neural network architectures, specifically focusing on the Scaled Dot-Product Attention and Multi-Head Attention mechanisms. Attention is a pivotal component in deep learning models, particularly in handling sequential data, as it allows the model to focus on different parts of the input data, enhancing the model's ability to make contextually informed decisions.\n",
       "\n",
       "The concept of Scaled Dot-Product Attention is introduced as a core component, where the attention mechanism computes the compatibility between a query vector and a series of key vectors. Each key vector is associated with a corresponding value vector. The compatibility is quantified through the dot product of the query and each key, normalized by the square root of the key's dimensionality, denoted as √dk. This normalization is crucial as it prevents the softmax function from squashing the values into a very narrow range, thereby preserving the gradient flow in the training process. The softmax function is then applied to these normalized dot products to generate weights, which are subsequently used to compute a weighted sum of the value vectors, producing the final output vector.\n",
       "\n",
       "The document elucidates that in practical implementations, the attention mechanism operates on a batch of queries and keys, encapsulated in matrices Q, K, and V, respectively, instead of individual vectors. This batch processing not only optimizes computation but also facilitates parallel processing, which is essential for handling large datasets and complex models efficiently. The output of this process is a matrix where each row corresponds to the output of a single query, effectively summarizing the relevant information from the input data as per the attention weights calculated.\n",
       "\n",
       "Moreover, the Multi-Head Attention mechanism is alluded to, which enhances the attention mechanism by allowing the model to jointly attend to information from different representation subspaces at different positions. This is achieved by applying the attention function multiple times in parallel with different linear projections of the query, key, and value vectors, and then concatenating the results. This approach provides a richer and more comprehensive representation of the data compared to a single attention head, leading to improved performance in various tasks, especially those involving language understanding and generation.\n",
       "\n",
       "---\n",
       "\n",
       "The section discusses the implementation of the attention mechanism in a transformer model, specifically focusing on the matrix operations involved and the comparison between two types of attention functions: additive attention and dot-product (multiplicative) attention. \n",
       "\n",
       "In the described model, the query (Q), key (K), and value (V) vectors are packed into matrices. The attention operation is then computed using the formula: \n",
       "\\[ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V \\]\n",
       "where \\(d_k\\) represents the dimensionality of the key vectors. This formula applies scaling by \\(1/\\sqrt{d_k}\\) to the dot product of the query and key matrices, followed by the application of a softmax function, and finally, the multiplication by the value matrix.\n",
       "\n",
       "The section then contrasts two common attention functions: additive and dot-product attention. Dot-product attention, as described, is essentially the method outlined above, with the key difference being the inclusion of the scaling factor \\(1/\\sqrt{d_k}\\). Additive attention, on the other hand, uses a feed-forward network with a single hidden layer to compute the compatibility function, which measures the relevance between each query and key pair. Despite having similar theoretical complexity, dot-product attention is highlighted for its practical advantages: it is faster and more space-efficient due to its reliance on optimized matrix multiplication routines.\n",
       "\n",
       "However, the text notes that for larger values of \\(d_k\\), additive attention tends to outperform dot-product attention when the latter lacks the scaling factor. This implies that while dot-product attention is generally more efficient, its performance can degrade with larger key dimensions unless proper scaling is applied. The inclusion of such scaling appears to be a critical adjustment for maintaining performance across a range of \\(d_k\\) values.\n",
       "\n",
       "---\n",
       "\n",
       "The section under review discusses two critical aspects of the attention mechanism in transformer models: scaling of the dot product attention and the implementation of multi-head attention.\n",
       "\n",
       "Firstly, the section addresses the issue of scaling in dot product attention. As the dimensionality of the keys and queries (denoted as dk) increases, the magnitude of the dot product between them also increases. This can lead to numerical instability, particularly in the softmax function, which is used to normalize these dot products into attention weights. When the dot products are large, the softmax function can produce very small gradients, which may impede the learning process. To mitigate this, the authors recommend scaling the dot product by a factor of \\( \\frac{1}{\\sqrt{dk}} \\). This scaling helps to stabilize the gradients and ensures that the attention mechanism operates effectively across different scales of input data.\n",
       "\n",
       "Secondly, the section introduces the concept of multi-head attention. Rather than using a single attention function with dmodel-dimensional keys, values, and queries, the model employs multiple attention functions, each with its own learned linear projections. Each of these 'heads' projects the queries, keys, and values into dk, dk, and dv dimensions, respectively, using distinct linear transformations. This allows the model to jointly attend to information from different representation subspaces at different positions, effectively capturing a broader range of dependencies within the input data. The outputs from these multiple attention heads are concatenated and passed through a final linear layer to obtain the attention output. This multi-head mechanism increases the model's capacity to capture complex patterns, contributing significantly to the overall performance of the transformer architecture.\n",
       "\n",
       "In summary, the reviewed section highlights the importance of proper scaling in dot product attention to manage numerical stability and the strategic use of multi-head attention to enable the model to capture a diverse set of information across different dimensions. These modifications are crucial for the robustness and effectiveness of transformer models in processing and understanding complex data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated, List\n",
    "import operator\n",
    "from IPython.display import Image, display\n",
    "from langgraph.constants import Send\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# PDF Upload and Text Extraction\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from the uploaded PDF using LangChain's PyPDFLoader.\"\"\"\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    pages = loader.load()\n",
    "    text = \"\\n\".join([page.page_content for page in pages])\n",
    "    return text\n",
    "\n",
    "# Chunking\n",
    "def chunk_text(text):\n",
    "    \"\"\"Chunks the extracted text for processing.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "# FAISS Storage with Hugging Face Embeddings\n",
    "def store_in_faiss(chunks):\n",
    "    \"\"\"Stores text chunks in FAISS for retrieval using Hugging Face embeddings.\"\"\"\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    faiss_index = FAISS.from_texts(chunks, embeddings)\n",
    "    return faiss_index\n",
    "\n",
    "# Define the structure of paper sections\n",
    "class PaperSection(BaseModel):\n",
    "    name: str = Field(description=\"Chunk ID for reference.\")\n",
    "    content: str = Field(description=\"Text content of the chunk.\")\n",
    "\n",
    "class PaperSections(BaseModel):\n",
    "    sections: List[PaperSection] = Field(description=\"Processed chunks of the research paper.\")\n",
    "\n",
    "# Graph state\n",
    "class State(TypedDict):\n",
    "    pdf_path: str  # PDF file path\n",
    "    sections: list[PaperSection]  # Extracted sections\n",
    "    reviewed_sections: Annotated[list, operator.add]  # Reviewed sections\n",
    "    final_review: str  # Final synthesized review report\n",
    "\n",
    "# Worker state\n",
    "class WorkerState(TypedDict):\n",
    "    section: PaperSection\n",
    "    reviewed_sections: Annotated[list, operator.add]\n",
    "\n",
    "# Nodes\n",
    "def pdf_processing(state: State):\n",
    "    \"\"\"Extracts text, chunks it, and stores in FAISS.\"\"\"\n",
    "    extracted_text = extract_text_from_pdf(state[\"pdf_path\"])\n",
    "    chunks = chunk_text(extracted_text)\n",
    "    faiss_index = store_in_faiss(chunks)\n",
    "\n",
    "    # Convert chunks to PaperSection format\n",
    "    processed_sections = [PaperSection(name=f\"Chunk {i+1}\", content=chunk) for i, chunk in enumerate(chunks)]\n",
    "    return {\"sections\": processed_sections}\n",
    "\n",
    "def llm_review(state: WorkerState):\n",
    "    \"\"\"Worker reviews a chunk of the paper.\"\"\"\n",
    "    review = llm.invoke(\n",
    "        [\n",
    "            SystemMessage(content=\"Perform an AI-driven review of the provided chunk in 300 words.\"),\n",
    "            HumanMessage(content=f\"Review this section: {state['section'].name}\\n\\n{state['section'].content}\"),\n",
    "        ]\n",
    "    )\n",
    "    return {\"reviewed_sections\": [review.content]}\n",
    "\n",
    "def synthesizer(state: State):\n",
    "    \"\"\"Synthesize the final research paper review.\"\"\"\n",
    "    reviewed_sections = state[\"reviewed_sections\"]\n",
    "    compiled_review = \"\\n\\n---\\n\\n\".join(reviewed_sections)\n",
    "    return {\"final_review\": compiled_review}\n",
    "\n",
    "def assign_reviewers(state: State):\n",
    "    \"\"\"Assign AI reviewers to each chunk.\"\"\"\n",
    "    return [Send(\"llm_review\", {\"section\": s}) for s in state[\"sections\"]]\n",
    "\n",
    "# Build workflow\n",
    "review_assistant_builder = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "review_assistant_builder.add_node(\"pdf_processing\", pdf_processing)\n",
    "review_assistant_builder.add_node(\"llm_review\", llm_review)\n",
    "review_assistant_builder.add_node(\"synthesizer\", synthesizer)\n",
    "\n",
    "# Add edges\n",
    "review_assistant_builder.add_edge(START, \"pdf_processing\")\n",
    "review_assistant_builder.add_conditional_edges(\"pdf_processing\", assign_reviewers, [\"llm_review\"])\n",
    "review_assistant_builder.add_edge(\"llm_review\", \"synthesizer\")\n",
    "review_assistant_builder.add_edge(\"synthesizer\", END)\n",
    "\n",
    "# Compile the workflow\n",
    "review_assistant = review_assistant_builder.compile()\n",
    "\n",
    "# Show the workflow\n",
    "display(Image(review_assistant.get_graph().draw_mermaid_png()))\n",
    "\n",
    "# Invoke the workflow with a sample PDF file\n",
    "state = review_assistant.invoke({\"pdf_path\": \"attention-1-4.pdf\"})\n",
    "\n",
    "Markdown(state[\"final_review\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
